{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2a4cde",
   "metadata": {},
   "source": [
    "# Train MLP Baseline (toy example and hyperparameter tuning)\n",
    "\n",
    "This notebook trains the `MLPBaseline` model from `model_classes/mlp_baseline.py` with a simple forward/backward loop and a small hyperparameter grid search.\n",
    "\n",
    "Notes:\n",
    "- For demonstration this uses a synthetic dataset (random features + labels). Replace the data-loading cell with your real dataset / `DataLoader` from `data_loaders.py` when ready.\n",
    "- Training loop is minimal: forward, compute loss, backward, optimizer step.\n",
    "- Hyperparameter tuning is a simple grid search over a few combos; it's not parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fe8cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root in sys.path: /home/quiet98k/Code/Fall25/hand-gestures-classifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Assuming you start the notebook from the training_scripts/ directory\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(\"Project root in sys.path:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e87cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Basic imports and helper utilities\n",
    "import os\n",
    "from itertools import product\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import model factory and dataset from the repo\n",
    "from model_classes.mlp_baseline import create_mlp_baseline\n",
    "from data_loaders import LandmarksDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the real LandmarksDataset from the repository\n",
    "# We flatten landmarks for the MLP (shape: N_landmarks * 2)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create train/val dataset instances (assumes data/annotations/{train,val} exist)\n",
    "annotations_root = \"../data/annotations\"\n",
    "train_ds = LandmarksDataset(annotations_root=annotations_root, split='train', flatten=True)\n",
    "val_ds = LandmarksDataset(annotations_root=annotations_root, split='val', flatten=True)\n",
    "\n",
    "# Infer input_dim and num_classes from dataset (keeps things consistent)\n",
    "first = train_ds[0]['landmarks']\n",
    "if isinstance(first, torch.Tensor):\n",
    "    input_dim = int(first.numel())\n",
    "else:\n",
    "    # Fallback: assume 42 features if something unusual happens\n",
    "    input_dim = 42\n",
    "num_classes = train_ds.num_classes\n",
    "\n",
    "print('Dataset sizes: train=', len(train_ds), 'val=', len(val_ds))\n",
    "print('Input dim (flattened landmarks):', input_dim, 'Num classes:', num_classes)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "# Quick smoke test: retrieve one batch and print basic shapes\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    print('Successfully retrieved a batch from train_loader')\n",
    "except Exception as e:\n",
    "    print('Error when iterating train_loader:', repr(e))\n",
    "    raise\n",
    "\n",
    "# Extract landmarks and labels from batch\n",
    "if isinstance(batch, dict):\n",
    "    xb = batch['landmarks']\n",
    "    yb = batch['label']\n",
    "else:\n",
    "    xb, yb = batch\n",
    "\n",
    "print('Batch shapes:', getattr(xb, 'shape', None), getattr(yb, 'shape', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cf0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation helpers\n",
    "def train_epoch(model: nn.Module, loader: DataLoader, optimizer, criterion, log_interval: int = 100) -> Dict[str, float]:\n",
    "    \"\"\"Run one training epoch and optionally print batch-level summaries.\n",
    "    Prints periodic batch summaries showing batch index, remaining batches, avg loss and acc for the window.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    window_loss = 0.0\n",
    "    window_correct = 0\n",
    "    window_samples = 0\n",
    "    for batch_idx, batch in enumerate(loader, start=1):\n",
    "        # Support both dict-style batches (from our Dataset) and tuple batches\n",
    "        if isinstance(batch, dict):\n",
    "            xb = batch['landmarks']\n",
    "            yb = batch['label']\n",
    "        else:\n",
    "            xb, yb = batch\n",
    "\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bsz = xb.size(0)\n",
    "        total_loss += loss.item() * bsz\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct = (preds == yb).sum().item()\n",
    "        total_correct += correct\n",
    "        total += bsz\n",
    "\n",
    "        # update window\n",
    "        window_loss += loss.item() * bsz\n",
    "        window_correct += correct\n",
    "        window_samples += bsz\n",
    "\n",
    "        # periodic print every `log_interval` batches\n",
    "        if log_interval and (batch_idx % log_interval == 0):\n",
    "            avg_loss = window_loss / window_samples if window_samples else 0.0\n",
    "            avg_acc = window_correct / window_samples if window_samples else 0.0\n",
    "            total_batches = len(loader) if hasattr(loader, '__len__') else '??'\n",
    "            print(f\"Batch {batch_idx}/{total_batches} | avg_loss={avg_loss:.4f} avg_acc={avg_acc:.4f}\")\n",
    "            # reset window counters\n",
    "            window_loss = 0.0\n",
    "            window_correct = 0\n",
    "            window_samples = 0\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / total,\n",
    "        'acc': total_correct / total,\n",
    "    }\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if isinstance(batch, dict):\n",
    "                xb = batch['landmarks']\n",
    "                yb = batch['label']\n",
    "            else:\n",
    "                xb, yb = batch\n",
    "\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / total,\n",
    "        'acc': total_correct / total,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple hyperparameter grid search (small grid for demo)\n",
    "results = []\n",
    "save_dir = os.path.join(os.getcwd(), 'training_outputs')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [3e-4, 1e-3],\n",
    "\n",
    "    'hidden_dims': [\n",
    "        (128, 64),\n",
    "        (256, 128),\n",
    "    ],\n",
    "\n",
    "    'dropout': [0.1, 0.3],\n",
    "\n",
    "    'batchnorm': [False, True],\n",
    "\n",
    "    'batch_size': [128, 256],\n",
    "\n",
    "    'max_epochs': [8, 12],\n",
    "}\n",
    "\n",
    "# Loss (kept separate for clarity)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# iterate grid\n",
    "# How often to print batch-level progress inside an epoch (set 0 to disable):\n",
    "log_interval = 500\n",
    "for lr, hidden_dims, dropout, batchnorm, batch_size, max_epochs in product(\n",
    "    param_grid['lr'], param_grid['hidden_dims'], param_grid['dropout'], param_grid['batchnorm'],\n",
    "    param_grid['batch_size'], param_grid['max_epochs']\n",
    "):\n",
    "    print('Running config:', {'lr': lr, 'hidden_dims': hidden_dims, 'dropout': dropout, 'batchnorm': batchnorm, 'batch_size': batch_size, 'max_epochs': max_epochs})\n",
    "\n",
    "    # build model and loaders\n",
    "    model = create_mlp_baseline(input_dim=input_dim, num_classes=num_classes, hidden_dims=hidden_dims, dropout=dropout, activation='relu', batchnorm=batchnorm)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # create DataLoaders directly (no helper)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state: dict[str, Any] | None = None\n",
    "\n",
    "    # history for this config (per-epoch)\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        prefix = f\"Config lr={lr} bs={batch_size} | Epoch {epoch}/{max_epochs}\"\n",
    "        tr = train_epoch(model, train_loader, optimizer, criterion, log_interval=log_interval)\n",
    "        # run validation inside epoch (after training pass)\n",
    "        va = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        # record history\n",
    "        history['train_loss'].append(tr['loss'])\n",
    "        history['train_acc'].append(tr['acc'])\n",
    "        history['val_loss'].append(va['loss'])\n",
    "        history['val_acc'].append(va['acc'])\n",
    "\n",
    "        # more detailed per-epoch message\n",
    "        print(f\"Epoch {epoch}/{max_epochs} | train_loss={tr['loss']:.4f} train_acc={tr['acc']:.4f} | val_loss={va['loss']:.4f} val_acc={va['acc']:.4f}\")\n",
    "\n",
    "        # save best model for this config\n",
    "        if va['acc'] > best_val_acc:\n",
    "            best_val_acc = va['acc']\n",
    "            best_state = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "\n",
    "    # persist best for this config\n",
    "    config_name = f\"mlp_lr{lr}_hd{hidden_dims[0]}-{hidden_dims[1]}_do{int(dropout*100)}_bn{int(batchnorm)}_bs{batch_size}_ep{max_epochs}\"\n",
    "    out_path = os.path.join(save_dir, config_name + '.pth')\n",
    "    if best_state is not None:\n",
    "        torch.save({'config': {'lr': lr, 'hidden_dims': hidden_dims, 'dropout': dropout, 'batchnorm': batchnorm, 'batch_size': batch_size, 'max_epochs': max_epochs}, 'best_val_acc': best_val_acc, 'state': best_state}, out_path)\n",
    "\n",
    "    results.append({'config': {'lr': lr, 'hidden_dims': hidden_dims, 'dropout': dropout, 'batchnorm': batchnorm, 'batch_size': batch_size, 'max_epochs': max_epochs}, 'best_val_acc': best_val_acc, 'path': out_path, 'history': history})\n",
    "\n",
    "# summarize results\n",
    "results_sorted = sorted(results, key=lambda r: r['best_val_acc'], reverse=True)\n",
    "print('Top results:')\n",
    "for r in results_sorted[:5]:\n",
    "    print(r['best_val_acc'], r['config'], r['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and do a quick inference check\n",
    "best = results_sorted[0]\n",
    "print('Best config:', best['config'], 'val_acc=', best['best_val_acc'])\n",
    "ckpt = torch.load(best['path'], map_location=device)\n",
    "cfg = ckpt['config']\n",
    "model = create_mlp_baseline(input_dim=input_dim, num_classes=num_classes, hidden_dims=tuple(cfg['hidden_dims']), dropout=cfg['dropout'], activation='relu', batchnorm=cfg['batchnorm'])\n",
    "model.load_state_dict(ckpt['state']['model_state'])\n",
    "model = model.to(device).eval()\n",
    "\n",
    "# run inference on a small batch\n",
    "batch = next(iter(val_loader))\n",
    "if isinstance(batch, dict):\n",
    "    xb = batch['landmarks']\n",
    "    yb = batch['label']\n",
    "else:\n",
    "    xb, yb = batch\n",
    "with torch.no_grad():\n",
    "    logits = model(xb.to(device))\n",
    "    preds = logits.argmax(dim=1).cpu()\n",
    "\n",
    "print('Sample preds:', preds[:10].tolist())\n",
    "print('Sample labels:', yb[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation history for the best config\n",
    "import matplotlib.pyplot as plt\n",
    "best = results_sorted[0]\n",
    "hist = best.get('history')\n",
    "if hist is None:\n",
    "    print('No history available for best config')\n",
    "else:\n",
    "    epochs = list(range(1, len(hist['train_loss']) + 1))\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, hist['train_loss'], label='train_loss')\n",
    "    plt.plot(epochs, hist['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, hist['train_acc'], label='train_acc')\n",
    "    plt.plot(epochs, hist['val_acc'], label='val_acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand-gestures-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
